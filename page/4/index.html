<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="it`s a description">
<meta name="keywords" content="ML AI">
<meta property="og:type" content="website">
<meta property="og:title" content="ShawShaw">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="ShawShaw">
<meta property="og:description" content="it`s a description">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ShawShaw">
<meta name="twitter:description" content="it`s a description">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/"/>





  <title>ShawShaw</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ShawShaw</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">stay real stay young</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/19/README/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaw Young">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShawShaw">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/19/README/" itemprop="url">README</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-19T15:19:51+08:00">
                2018-10-19
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  313
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="博客README"><a href="#博客README" class="headerlink" title="博客README?"></a>博客README?</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言:"></a>前言:</h2><blockquote>
<p>特别菜的一个研究生, 如果论文和轮子都有了, 就去互联网. 如果只有论文, 那就去研究所. 前路未卜, 还想来一句紧张刺激的吃鸡, 还有那台吃灰的PS4和键盘, 还有备受冷漠的dove和fender, 时间像…., 挤一挤都不会有多少 .</p>
<p>11月12号:  看了大牛的博客,还有最近新鲜感在忙碌中慢慢淡化, 有感 , 发现自己感性与品位在逐渐的退化,  很难再像高中的晨读, 或者本科那会宿舍的一罐啤酒, 加上无关世界的一首歌, 就能把自己感动;  还发现, 有的大牛, 写了很棒的技术博客, 但情感上却像是不问世事, 把自己封闭的孩子(也是自己的选择) , 而有的, 却是在每个他在的每个角落散发着他所坚持的 “酷”.</p>
<p>也不知道是不是成长伴随的一定是感动消逝  3334455554444444  (忽然发现我这”蝴蝶键盘4这个不好使了, 有延迟…. wtf ???? 大概重启就好了”)  , 开始在Life下 , 写下自己要做的事情, </p>
</blockquote>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>​    Life</p>
<p>​    Music</p>
<p>​    Image Rerieval</p>
<p>​    Love</p>
<h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><p>​    cpp</p>
<p>​    python</p>
<p>​    electric guitar</p>
<p>​    guitar</p>
<p>​    CBIR</p>
<p>#### </p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/19/VLAD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaw Young">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShawShaw">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/19/VLAD/" itemprop="url">VLAD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-19T14:44:48+08:00">
                2018-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Image-Rerieval/" itemprop="url" rel="index">
                    <span itemprop="name">Image Rerieval</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  336
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="VALD-特征编码"><a href="#VALD-特征编码" class="headerlink" title="VALD 特征编码"></a>VALD 特征编码</h1><h2 id="1-VALD"><a href="#1-VALD" class="headerlink" title="1. VALD"></a>1. VALD</h2><p>特征数据集:</p>
<p>$X = { x_1, …, x_n }$  每个特征向量$x_i$ 都是d维的向量. </p>
<ol>
<li><p>聚类(clustering) :<br>K-means 将n个d维的特征 $x_i \in  R^d , i=1,2,..,n$<br>保存类中心向量 $c = {u_1,…,u_k}$  </p>
</li>
<li><p>集成(aggregation):</p>
<p>求出残差向量 $v^i = \sum \limits_{x:q(x) = u_i }x - u_i$</p>
<p>得到k个d维子向量.  讲k个子向量拉成一个 $D=k*d$的一维向量</p>
<p>$v=[v^1,…,v^k] = [ v_1,…,v_D]$  </p>
</li>
<li><p>归一化:  (power-law normalization) </p>
<p>$v_j := |v_j|^a * sign(v_j), j =1, 2, …, D$ 其中 $\alpha \le 1$  </p>
<p>作用是抑制数值大的数同时提升数值小的数</p>
<p>$v:= \frac v{||v||}$</p>
<p>幂律归一化的目的是主要为了减少某些特征出现次数特别多（visual bursts）带来的影响，这是因为出现次数特别多时聚类中心就在它附近，相应的残差就很小;L2范数归一化的目的主要是为了使得特征向量范数为1，使得对特征的比较是在同一个尺度上，比如可以用来减少同一个物体在不同光照下由于光照等因素带来的特征差异。</p>
<p>在进行特征匹配时，VLAD特征之间的相似性是通过内积来定义，这种相似性受聚类的影响较大。</p>
<p>原文：<a href="https://blog.csdn.net/CHIERYU/article/details/65441242" target="_blank" rel="noopener">https://blog.csdn.net/CHIERYU/article/details/65441242</a> </p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/18/Statical-Learning-kNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaw Young">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShawShaw">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/18/Statical-Learning-kNN/" itemprop="url">Statical-Learning-kNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-18T10:32:07+08:00">
                2018-10-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1.3k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  4
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="3-2-kNN-Model"><a href="#3-2-kNN-Model" class="headerlink" title="3.2 kNN Model"></a>3.2 kNN Model</h2><h3 id="3-2-1模型"><a href="#3-2-1模型" class="headerlink" title="3.2.1模型"></a>3.2.1模型</h3><p>cell</p>
<p>class label </p>
<p>每个cell的类别是确定的</p>
<p>距离度量、k值选择、分类决策构成</p>
<h3 id="3-2-2-距离度量"><a href="#3-2-2-距离度量" class="headerlink" title="3.2.2 距离度量"></a>3.2.2 距离度量</h3><p>特征空间一般是 n维实数向量空间 $R^n$<br>$$<br>L_p(x_i,y_i) = (\sum|x_i^{(l)} - x_j^{(l)}|^p)^{1/p}<br>$$<br>p = 2 时 ，Euclidean distance</p>
<p>p = 1时， Manhattan distance</p>
<p>p = ∞ 时，各个坐标距离的最大值</p>
<h3 id="3-2-3-k值的选择"><a href="#3-2-3-k值的选择" class="headerlink" title="3.2.3 k值的选择"></a>3.2.3 k值的选择</h3><p>k值小，相当于邻域较小，近似误差减小，只有与实例较近的（相似的）才会对预测结果起作用，但估计误差会增大，对临近实例非常敏感。即会使模型变的复杂，易发生过拟合。</p>
<p>用交叉验证法来选去最优k</p>
<h3 id="3-2-4-分类决策规则"><a href="#3-2-4-分类决策规则" class="headerlink" title="3.2.4 分类决策规则"></a>3.2.4 分类决策规则</h3><h2 id="3-3-实现：kd树"><a href="#3-3-实现：kd树" class="headerlink" title="3.3 实现：kd树"></a>3.3 实现：kd树</h2><hr>
<p>​    Pal/King提出的模糊边缘检测算法由于引人了模糊的思想因而处理效果明显优于传统方法。该算法首先通过阈值来定义隶属函数将原始图像映射到模糊特征平面；然后利用模糊增强处理来提高区域之间的层次加强边缘两侧的对比度；最后根据一定的判别准则提取出图像的边缘。</p>
<hr>
<p>​    图像的边缘检测是图像分割的一种重要手段，是图像处理和计算机视觉中的基本问题，通过标识数字图像中亮度变化明显的点，来捕捉图像属性中的显著变化，包括深度上的不连续、表面方向的不连续、物质属性变化、和场景照明变化，并能够大幅减少数据量，在保留重要的结构属性的同时，剔除弱相关信息。</p>
<pre><code>常用的边缘检测算子是利用边缘处一阶导数的极值，大量使用的是一些局部微分算子，如Roberts梯度算子、Sobel梯度算子、Laplacian二阶差分算子等。这些算法的主要优点是形式简单，易于实现，速度快；但这些算法只考虑到局部的急剧变化，特别是颜色、亮度等的急剧变化，通过这些特征来找边缘缺点是定位精度差，常常会产生一些断续的、不完整的边缘信息。
</code></pre><p>​    2013年，开始有人使用数据驱动的方法来学习怎样联合颜色、亮度、梯度这些特征来做边缘检测，还有些流行的方法，比如Pb, gPb，StrucutredEdge，下图是近年最具代表性的工作的PR曲线对比（采自Berkekey Segmentation Benchmark）。</p>
<pre><code>而模糊边缘检测算法首次将模糊集理论引入到图像的边缘检测算法中。由于图像中物体边界所具有的不确定性往往是模糊性，因此该方法能有效的将物体从背景中分离出来。
</code></pre><hr>
<p>​    算法思想首先用隶属度函数将图像映射成一个模糊隶属度矩阵；然后进行模糊增强处理，以增强边缘信息；接着再对模糊隶属度矩阵进行对应的逆变换，以得到经过增强后的图像，最后提取出图像的边缘。</p>
<p>​         第一步：将待处理的图像映射为一个模糊矩阵，图像I记为<br>$$<br>I =  (\bigcup^M_{m=1}\bigcup^N_{n=1}\mu_{mn}/l_{mn)}<br>$$<br>​        <em>其中，$\mu_{mn}/l_{mn}$表示矩阵中第（m，n）个模糊单点集的隶属度函数/该点的灰度级。</em></p>
<p>​    算法定义的隶属函数为<br>$$<br>\mu_{mn} = G(l_{mn}) = ( 1 + (L-1-l_{mn})/F_d)^{-F_e}<br>$$<br>​        <em>$F_d$为倒数型模糊因子，$F_e$为指数型模糊因子</em></p>
<p>​    第二步：在模糊空间利用增强算子对图像做模糊增强处理，即通过改变像素来增强边缘两侧像素灰度的对比度，减少图像灰度层次。模糊增强算子定义为</p>
<p>​<br>$$<br>\mu^{‘}_{mn} = T_r(\mu_{mn}) = T_I(T_{r-1}(\mu_{mn}))  ,_{r = 1,2,…}<br>$$</p>
<p>$$<br>T_I(\mu_{mn}) = f(x)=\left{<br>\begin{aligned}<br>&amp;2(\mu_{mn})^2 &amp; \ 0\le\mu_{mn}\le0.5 \<br>&amp;1-2(1-\mu_{mn})^2 &amp;\ 0.5 &lt;\mu_{mn}\le1<br>\end{aligned}<br>\right.<br>$$</p>
<p>​    第三步，对$\mu_{mn}^{‘}$进行逆变换，从而得到经过模糊增强后的图像$X^{‘}$ , 其中的像素灰度级$l_{mn}^{‘}$:<br>$$<br>l_{mn}^{‘} = G^{-1}(\mu_{mn}^{‘})<br>$$<br>​    第四步，提取边缘，使用min/max算子，定义图像的边缘为矩阵：<br>$$<br>E_{edge} [l^{‘’}<em>{mn} ]</em>{M\times N}<br>$$<br>​    当采用min算子时，$l^{‘’}<em>{mn}$:<br>$$<br>l^{‘’}</em>{mn} = |l^{‘}<em>{mn} - min</em>{\Omega}(l^{‘}_{ij})|, (i,j) \in \Omega<br>$$<br>​    其中：$\Omega$通常取（i，j）为中心的3x3窗口</p>
<hr>
<p>​    该算法的缺陷是:实际应用中渡越点$l_c$的选取一般凭经验或根据灰度统计直方图确定，而此算法直接设定为0.5，需要多次试探和比较才能找到十分浪费时间。此外 隶属函数中的参数$F_d F_e$ 具有可调性，其合理选取将在很大程度上直接影响图像处理的效果。然而，目前还没有一个合理的指导原则来选。</p>
<p>​    而目前已存在通过图像分割或者改进阈值选取方法，采用新的隶属度函数、模糊平滑处理来减少噪声影响等方法。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/16/test-my-site/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaw Young">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShawShaw">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/16/test-my-site/" itemprop="url">test_my_site</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-16T02:12:05+08:00">
                2018-10-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  1
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  1
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>hexo_test</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/16/ANN(Approximate Nearest  Neighbor)  Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Shaw Young">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ShawShaw">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/16/ANN(Approximate Nearest  Neighbor)  Search/" itemprop="url">Note_ML_ANN(Approximate Nearest  Neighbor)  Search</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-16T02:12:05+08:00">
                2018-10-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  18
                </span>
              
            </div>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="笔记-ANN-Approximate-Nearest-Neighbor-Search"><a href="#笔记-ANN-Approximate-Nearest-Neighbor-Search" class="headerlink" title="笔记: ANN(Approximate Nearest  Neighbor)  Search"></a>笔记: ANN(Approximate Nearest  Neighbor)  Search</h1><p>原文 : <a href="https://yongyuan.name/blog/ann-search.html" target="_blank" rel="noopener">https://yongyuan.name/blog/ann-search.html</a></p>
<p>对  ANN 宏观认知 :  <strong>brute-force搜索的方式, 对全空间进行搜索, 为了加快查找速度, 几乎所有的 ANN 方法都是通过对全空间分割, 将其分割成很多小的子空间. 搜索时通过某种方式, 快速锁定在某一某几子空间, 然后在该几个子空间里做遍历</strong> . 正因为缩减了遍历范围,ANN能够处理大规模数据的索引.</p>
<p>ANN分类: 基于树的方法,  哈希方法,  矢量化方法. 这三种方法里面, 典型方法:哈希方法,矢量化方法. </p>
<h2 id="树🌲"><a href="#树🌲" class="headerlink" title="树🌲"></a>树🌲</h2><p>几乎所有ANN 都是对全空间的划分, 树也是. KD树, ANNOY. </p>
<h4 id="KD树"><a href="#KD树" class="headerlink" title="KD树"></a>KD树</h4><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fwb9eyuddyj30gf0a1mxd.jpg" alt="drawing"></p>
<p>选择向哪一维度进行划分的 标准, 是 求每一个维度的方差, 选择方差最大的那个维度.                     </p>
<p>一个问题:<strong>为何要选择方差作为维度划分选取的标准</strong> ? </p>
<p><strong>方差的大小可以反映数据的波动性</strong> : 方差大表示数据波动性越大, 选择方差最大大的开始划分, 可以使所需的划分面数目最小, 反映到树数据结构上, 可以使 构建的 KD树的深度尽可能的小.</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwb9wuro6gj30du0ci74i.jpg" alt="drawing">假设不以方差最大的x轴为划分面(x_var = 16.25)，而是以y轴(y_var = 0.0)轴为划分面，如图中虚线所示，可以看到，该划分使得图中的四个点都落入在同一个子空间中，从而使得该划分成为一个无效的划分，体现在以树结构上，就是多了一层无用的树深度。而以x轴为初始划分则不同(图像实线所示)，以x轴为初始划分可以得到数据能够比较均匀的散布在左右两个子空间中，从而使得整体的查找时间能够最短。注意，在实际的kd树划分的时候，并不是图中虚线所示，而是选取中值最近的点。上面示意图构建的具体kd树如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [9]: kdtree.visualize(tree)</span><br><span class="line"></span><br><span class="line">                       (9, 4)</span><br><span class="line"></span><br><span class="line">             (2, 4)              (10, 4)</span><br><span class="line"></span><br><span class="line">        (1, 4)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>kd-trees are not suitable for efficiently finding the nearest neighbour in high dimensional spaces.<br>In very high dimensional spaces, the curse of dimensionality causes the algorithm to need to visit many more branches than in lower dimensional spaces. In particular, when the number of points is only slightly higher than the number of dimensions, the algorithm is only slightly better than a linear search of all of the points.</p>
</blockquote>
<h3 id="Annoy"><a href="#Annoy" class="headerlink" title="Annoy"></a>Annoy</h3><p>Annoy是<a href="https://github.com/erikbern" target="_blank" rel="noopener">Erik Bernhardsson</a>写的一个以树为数据结构的近似最近邻搜索库，并用在<a href="https://www.spotify.com/" target="_blank" rel="noopener">Spotify</a>的推荐系统中。Annoy的核心是不断用选取的两个质心的法平面对空间进行分割，最终将每一个区分的子空间里面的样本数据限制在K以内。对于待插入的样本$x_i$，从根节点依次使用法向量跟$x_i$做内积运算，从而判断使用法平面的哪一边（左子树or右子树）。对于查询向量qiqi，采用同样的方式（在树结构上体现为从根节点向叶子节点递归遍历），即可定位到跟qiqi在同一个子空间或者邻近的子空间的样本，这些样本即为qiqi近邻。</p>
<p>为了提高查询的召回，Annoy采用建立多棵树的方式，这种做法是一种非常常见的做法，比如NV-tree也采用这种方式，哈希方法采用多表的哈希方法。</p>
<p>值得注意的是，Annoy如果不保存原始特征，则Annoy只能返回查询的k个近邻，至于这k个里面的排序顺序是怎么样的，它是不知道的，如果需要知道，需要对这k个返回的结果，获取原始特征，再计算各自的相似度，排序一下即可得到这k个结果的排序。</p>
<p>根据Annoy的定义的节点数据结构，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">struct ANNOY_NODE_ATTRIBUTE Node &#123;</span><br><span class="line">S n_descendants;</span><br><span class="line">union &#123;</span><br><span class="line">  S children[2]; // Will possibly store more than 2</span><br><span class="line">  T norm;</span><br><span class="line">&#125;;</span><br><span class="line">T dot_factor;</span><br><span class="line">T v[1]; // We let this one overflow intentionally. Need to allocate at least 1 to make GCC happy</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中<code>T v[1]</code>保存原始特征，保存原始的特征的坏处是造成占用内存过大，索引文件过大。</p>
<h3 id="哈希hash"><a href="#哈希hash" class="headerlink" title="哈希hash"></a>哈希hash</h3><p>哈希，顾名思义，就是将连续的实值散列化为0、1的离散值。在散列化的过程中，对散列化函数(也就是哈希函数)有一定的要求。根据学习的策略，可以将哈希方法分为无监督、有监督和半监督三种类型。在评估某种哈希方法用于图像检索的检索精度时，可以使用knn得到的近邻作为ground truth，也可以使用样本自身的类别作为ground truth。所以在实际评估准确度的时候，根据ground truth的定义，这里面是有一点小的trick的。通常对于无监督的哈希图像检索方法，由于我们使用的都是未标记的数据样本，所以我们会很自然的采用knn得到的近邻作为ground truth，但是对于图像检索的这一任务时，在对哈希函数的构造过程中，通常会有“相似的样本经编码后距离尽可能的近，不相似的样本编码后则尽可能的远”这一基本要求，这里讲到的相似，指语义的相似，因而你会发现，编码的基本要求放在无监督哈希方法里，似乎与采用knn得到的近邻作为ground truth的评价方式有些南辕北辙。对无监督哈希方法的ground truth一点小的疑惑在小白菜读书的时候就心存这样的困惑，一直悬而未解。当然，在做无监督的图像哈希方法，采用样本自身的类别作为ground truth是毋庸置疑的。</p>
<p>小白菜读书那会儿，研究了很多的哈希图像检索方法（见<a href="https://github.com/willard-yuan/hashing-baseline-for-image-retrieval" target="_blank" rel="noopener">hashing-baseline-for-image-retrieval</a>），有时候总会给一些工程实践上的错觉（在今天看来是这样的），即新论文里的方法远远碾压经典的方法，那是不是在实际中这些方法就很work很好使。实践的经历告诉小白菜，还是经典的东西更靠谱，不是因为新的方法不好，而是新的事物需要经过时间的沉淀与优化。</p>
<p>所以，这里不会对近两年的哈希方法做铺陈，而是聊一聊工程中在要使用到哈希方法的场景下一般都会选用的局部敏感哈希（Local Sensitive Hashing, LSH）。</p>
<h4 id="Local-Sensitive-Hashing"><a href="#Local-Sensitive-Hashing" class="headerlink" title="Local Sensitive Hashing"></a>Local Sensitive Hashing</h4><p>关于LSH的介绍，小白菜以为，<a href="https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer" target="_blank" rel="noopener">Locality-Sensitive Hashing: a Primer</a>这个讲解得极好，推荐一读。下面是小白菜结合自己的理解，提炼的一些在小白菜看来需要重点理解的知识（附上LSH划分空间示意图，在进行理解的时候可以参照改图）。</p>
<p><img src="http://ose5hybez.bkt.clouddn.com/2017/0408/lsh_ex_zps0lryoykz.PNG" alt="drawing"></p>
<h4 id="局部敏感是啥？"><a href="#局部敏感是啥？" class="headerlink" title="局部敏感是啥？"></a>局部敏感是啥？</h4><p>当一个函数（或者更准确的说，哈希函数家族）具有如下属性的时候，我们说该哈希函数是局部敏感的：相近的样本点对比相远的样本点对更容易发生碰撞。</p>
<h4 id="用哈希为什么可以加速查找？"><a href="#用哈希为什么可以加速查找？" class="headerlink" title="用哈希为什么可以加速查找？"></a>用哈希为什么可以加速查找？</h4><p>对于brute force搜索，需要遍历数据集中的所有点，而使用哈希，我们首先找到查询样本落入在哪个cell(即所谓的桶)中，如果空间的划分是在我们想要的相似性度量下进行分割的，则查询样本的最近邻将极有可能落在查询样本的cell中，如此我们只需要在当前的cell中遍历比较，而不用在所有的数据集中进行遍历。</p>
<h4 id="为什么要用多表哈希？"><a href="#为什么要用多表哈希？" class="headerlink" title="为什么要用多表哈希？"></a>为什么要用多表哈希？</h4><p>对于单表哈希，当我们的哈希函数数目K取得太大，查询样本与其对应的最近邻落入同一个桶中的可能性会变得很微弱，针对这个问题，我们可以重复这个过程L次，从而增加最近邻的召回率。这个重复L次的过程，可以转化为构建L个哈希表，这样在给定查询样本时，我们可以找到L个哈希桶（每个表找到一个哈希桶），然后我们在这L个哈希表中进行遍历。这个过程相当于构建了K*L个哈希函数(注意是“相当”，不要做“等价”理解)。</p>
<h4 id="多表哈希中哈希函数数目K和哈希表数目L如何选取？"><a href="#多表哈希中哈希函数数目K和哈希表数目L如何选取？" class="headerlink" title="多表哈希中哈希函数数目K和哈希表数目L如何选取？"></a>多表哈希中哈希函数数目K和哈希表数目L如何选取？</h4><p>哈希函数数目K如果设置得过小，会导致每一个哈希桶中容纳了太多的数据点，从而增加了查询响应的时间；而当K设置得过大时，会使得落入每个哈希桶中的数据点变小，而为了增加召回率，我们需要增加L以便构建更多的哈希表，但是哈希表数目的增加会导致更多的内存消耗，并且也使得我们需要计算更多的哈希函数，同样会增加查询相应时间。这听起来非常的不妙，但是在K过大或过小之间仍然可以找到一个比较合理的折中位置。通过选取合理的K和L，我们可以获得比线性扫描极大的性能提升。</p>
<h4 id="Multiprobe-LSH是为了解决什么问题？"><a href="#Multiprobe-LSH是为了解决什么问题？" class="headerlink" title="Multiprobe LSH是为了解决什么问题？"></a>Multiprobe LSH是为了解决什么问题？</h4><p>多probe LSH主要是为了提高查找准确率而引入的一种策略。首先解释一下什么是Multiprobe。对于构建的L个哈希表，我们在每一个哈希表中找到查询样本落入的哈希桶，然后再在这个哈希桶中做遍历，而Multiprobe指的是我们不止在查询样本所在的哈希桶中遍历，还会找到其他的一些哈希桶，然后这些找到的T个哈希桶中进行遍历。这些其他哈希桶的选取准则是：跟查询样本所在的哈希桶邻近的哈希桶，“邻近”指的是汉明距离度量下的邻近。</p>
<p>通常，如果不使用Multiprobe，我们需要的哈希表数目L在100到1000之间，在处理大数据集的时候，其空间的消耗会非常的高，幸运地是，因为有了上面的Multiprobe的策略，LSH在任意一个哈希表中查找到最近邻的概率变得更高，从而使得我们能到减少哈希表的构建数目。</p>
<p>综上，对于LSH，涉及到的主要的参数有三个：</p>
<ul>
<li>K，每一个哈希表的哈希函数（空间划分）数目</li>
<li>L，哈希表（每一个哈希表有K个哈希函数）的数目</li>
<li>T，近邻哈希桶的数目，即the number of probes</li>
</ul>
<p>这三个设置参数可以按照如下顺序进行：首先，根据可使用的内存大小选取L，然后在K和T之间做出折中：哈希函数数目K越大，相应地，近邻哈希桶的数目的数目T也应该设置得比较大，反之K越小，L也可以相应的减小。获取K和L最优值的方式可以按照如下方式进行：对于每个固定的K，如果在查询样本集上获得了我们想要的精度，则此时T的值即为合理的值。在对T进行调参的时候，我们不需要重新构建哈希表，甚至我们还可以采用二分搜索的方式来加快T参数的选取过程。</p>
<h3 id="LSH开源工具包"><a href="#LSH开源工具包" class="headerlink" title="LSH开源工具包"></a>LSH开源工具包</h3><p>关于LSH开源工具库，有很多，这里推荐两个LSH开源工具包：<a href="https://github.com/kayzhu/LSHash" target="_blank" rel="noopener">LSHash</a>和<a href="https://falconn-lib.org/" target="_blank" rel="noopener">FALCONN</a>, 分别对应于学习和应用场景。</p>
<h4 id="LSHash"><a href="#LSHash" class="headerlink" title="LSHash"></a>LSHash</h4><p><a href="https://github.com/kayzhu/LSHash" target="_blank" rel="noopener">LSHash</a>非常适合用来学习，里面实现的是最经典的LSH方法，并且还是单表哈希。哈希函数的系数采用随机的方式生成，具体代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def _generate_uniform_planes(self):</span><br><span class="line">    &quot;&quot;&quot; Generate uniformly distributed hyperplanes and return it as a 2D</span><br><span class="line">    numpy array.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    return np.random.randn(self.hash_size, self.input_dim)</span><br></pre></td></tr></table></figure>
<p><code>hash_size</code>为哈希函数的数目，即前面介绍的K。整个框架，不论是LSH的哈希函数的生成方式，还是LSH做查询，都极其的中规中矩，所以用来作为了解LSH的过程，再适合不过。如果要在实用中使用LSH，可以使用<a href="https://falconn-lib.org/" target="_blank" rel="noopener">FALCONN</a>。</p>
<h4 id="FALCONN"><a href="#FALCONN" class="headerlink" title="FALCONN"></a>FALCONN</h4><h2 id="矢量量化方法"><a href="#矢量量化方法" class="headerlink" title="矢量量化方法"></a>矢量量化方法</h2><p>矢量量化方法，即vector quantization，其具体定义为：<a href="http://blog.pluskid.org/?p=57" target="_blank" rel="noopener">将一个向量空间中的点用其中的一个有限子集来进行编码的过程</a>。在矢量量化编码中，<a href="https://baike.baidu.com/item/%E7%9F%A2%E9%87%8F%E9%87%8F%E5%8C%96" target="_blank" rel="noopener">关键是码本的建立和码字搜索算法</a>。比如常见的聚类算法，就是一种矢量量化方法。而在ANN近似最近邻搜索中，向量量化方法又以乘积量化(PQ, Product Quantization)最为典型。在之前的博文<a href="https://yongyuan.name/blog/cbir-technique-summary.html" target="_blank" rel="noopener">基于内容的图像检索技术</a>的最后，对PQ乘积量化的方法做过简单的概要。在这一小节里，小白菜结合自己阅读的论文和代码对PQ乘积量化、倒排乘积量化(IVFPQ)做一种更加直观的解释。</p>
<h3 id="PQ乘积量化"><a href="#PQ乘积量化" class="headerlink" title="PQ乘积量化"></a>PQ乘积量化</h3><p>PQ乘积量化的核心思想还是聚类，或者说具体应用到ANN近似最近邻搜索上，K-Means是PQ乘积量化子空间数目为1的特例。PQ乘积量化生成码本和量化的过程可以用如下图示来说明：</p>
<p><img src="http://ose5hybez.bkt.clouddn.com/2017/0408/PQ_zpsybhprown.PNG" alt="img"></p>
<p>在训练阶段，针对N个训练样本，假设样本维度为128维，我们将其切分为4个子空间，则每一个子空间的维度为32维，然后我们在每一个子空间中，对子向量采用K-Means对其进行聚类(图中示意聚成256类)，这样每一个子空间都能得到一个码本。这样训练样本的每个子段，都可以用子空间的聚类中心来近似，对应的编码即为类中心的ID。如图所示，通过这样一种编码方式，训练样本仅使用的很短的一个编码得以表示，从而达到量化的目的。对于待编码的样本，将它进行相同的切分，然后在各个子空间里逐一找到距离它们最近的类中心，然后用类中心的id来表示它们，即完成了待编码样本的编码。</p>
<p>正如前面所说的，在矢量量化编码中，关键是码本的建立和码字的搜索算法，在上面，我们得到了建立的码本以及量化编码的方式。剩下的重点就是查询样本与dataset中的样本距离如何计算的问题了。</p>
<p>在查询阶段，PQ同样在计算查询样本与dataset中各个样本的距离，只不过这种距离的计算转化为间接近似的方法而获得。PQ乘积量化方法在计算距离的时候，有两种距离计算方式，一种是对称距离，另外一种是非对称距离。非对称距离的损失小(也就是更接近真实距离)，实际中也经常采用这种距离计算方式。下面过程示意的是查询样本来到时，以非对称距离的方式(红框标识出来的部分)计算到dataset样本间的计算示意：</p>
<p><img src="http://ose5hybez.bkt.clouddn.com/2017/0408/PQ_search_zpskgugtocx.PNG" alt="img"></p>
<p>具体地，查询向量来到时，按训练样本生成码本的过程，将其同样分成相同的子段，然后在每个子空间中，计算子段到该子空间中所有聚类中心得距离，如图中所示，可以得到4*256个距离，这里为便于后面的理解说明，小白菜就把这些算好的距离称作距离池。在计算库中某个样本到查询向量的距离时，比如编码为(124, 56, 132, 222)这个样本到查询向量的距离时，我们分别到距离池中取各个子段对应的距离即可，比如编码为124这个子段，在第1个算出的256个距离里面把编号为124的那个距离取出来就可，所有子段对应的距离取出来后，将这些子段的距离求和相加，即得到该样本到查询样本间的非对称距离。所有距离算好后，排序后即得到我们最终想要的结果。</p>
<p>从上面这个过程可以很清楚地看出PQ乘积量化能够加速索引的原理：即将全样本的距离计算，转化为到子空间类中心的距离计算。比如上面所举的例子，原本brute-force search的方式计算距离的次数随样本数目N成线性增长，但是经过PQ编码后，对于耗时的距离计算，只要计算4*256次，几乎可以忽略此时间的消耗。另外，从上图也可以看出，对特征进行编码后，可以用一个相对比较短的编码来表示样本，自然对于内存的消耗要大大小于brute-force search的方式。</p>
<p>在某些特殊的场合，我们总是希望获得精确的距离，而不是近似的距离，并且我们总是喜欢获取向量间的余弦相似度（余弦相似度距离范围在[-1,1]之间，便于设置固定的阈值），针对这种场景，可以针对PQ乘积量化得到的前top@K做一个brute-force search的排序。</p>
<h3 id="倒排乘积量化"><a href="#倒排乘积量化" class="headerlink" title="倒排乘积量化"></a>倒排乘积量化</h3><p>倒排PQ乘积量化(IVFPQ)是PQ乘积量化的更进一步加速版。其加速的本质逃不开小白菜在最前面强调的是加速原理：<strong>brute-force搜索的方式是在全空间进行搜索，为了加快查找的速度，几乎所有的ANN方法都是通过对全空间分割，将其分割成很多小的子空间，在搜索的时候，通过某种方式，快速锁定在某一（几）子空间，然后在该（几个）子空间里做遍历</strong>。在上一小节可以看出，PQ乘积量化计算距离的时候，距离虽然已经预先算好了，但是对于每个样本到查询样本的距离，还是得老老实实挨个去求和相加计算距离。但是，实际上我们感兴趣的是那些跟查询样本相近的样本（小白菜称这样的区域为感兴趣区域），也就是说老老实实挨个相加其实做了很多的无用功，如果能够通过某种手段快速将全局遍历锁定为感兴趣区域，则可以舍去不必要的全局计算以及排序。倒排PQ乘积量化的”倒排“，正是这样一种思想的体现，在具体实施手段上，采用的是通过聚类的方式实现感兴趣区域的快速定位，在倒排PQ乘积量化中，聚类可以说应用得淋漓尽致。</p>
<p>倒排PQ乘积量化整个过程如下图所示：</p>
<p><img src="http://ose5hybez.bkt.clouddn.com/2017/0408/IVFPQ_zpswvosr8a6.PNG" alt="img"></p>
<p>在PQ乘积量化之前，增加了一个粗量化过程。具体地，先对N个训练样本采用K-Means进行聚类，这里聚类的数目一般设置得不应过大，一般设置为1024差不多，这种可以以比较快的速度完成聚类过程。得到了聚类中心后，针对每一个样本x_i，找到其距离最近的类中心c_i后，两者相减得到样本x_i的残差向量(x_i-c_i)，后面剩下的过程，就是针对(x_i-c_i)的PQ乘积量化过程，此过程不再赘述。</p>
<p>在查询的时候，通过相同的粗量化，可以快速定位到查询向量属于哪个c_i（即在哪一个感兴趣区域），然后在该感兴趣区域按上面所述的PQ乘积量化距离计算方式计算距离。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Shaw Young</p>
              <p class="site-description motion-element" itemprop="description">it`s a description</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shaw Young</span>

  
</div>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
<span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>

    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  


  
</body>
</html>
